{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]\n",
      " [5]]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This PolynomialFeatures instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m      6\u001b[0m poly \u001b[39m=\u001b[39m PolynomialFeatures(\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m (poly\u001b[39m.\u001b[39;49mtransform(X))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_polynomial.py:339\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    311\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Transform data to polynomial features.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m        `csr_matrix`.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    341\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m    342\u001b[0m         X, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mFLOAT_DTYPES, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, accept_sparse\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    343\u001b[0m     )\n\u001b[1;32m    345\u001b[0m     n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[1;32m   1386\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1387\u001b[0m     ]\n\u001b[1;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1390\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This PolynomialFeatures instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#from preprocessing.polynomial_features import PolynomialFeatures\n",
    "import numpy as np\n",
    "X = np.arange(6)\n",
    "print(X.reshape(-1,1))\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "(poly.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "2\n",
      "()\n",
      "(0,)\n",
      "(1,)\n",
      "(0, 0)\n",
      "(0, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from itertools import combinations_with_replacement as combinations_w_r\n",
    "max_degree = 2\n",
    "X = np.arange(2)\n",
    "\n",
    "print(X)\n",
    "n_features = X.shape[0]\n",
    "print(n_features)\n",
    "comb = combinations_w_r\n",
    "start = 1\n",
    "iter = chain.from_iterable(\n",
    "    comb(range(n_features), i) for i in range(start, max_degree + 1)\n",
    ")\n",
    "if True:\n",
    "    iter = chain(comb(range(n_features), 0), iter)\n",
    "for i in iter:\n",
    "    print(i)\n",
    "l=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<itertools.chain object at 0x7fbeae4552d0>\n"
     ]
    }
   ],
   "source": [
    "print(iter)\n",
    "for i in iter:\n",
    "    out=1\n",
    "    print(i)\n",
    "    for j in i:\n",
    "        out*=X[:,j]\n",
    "    print(out,'**')\n",
    "    l.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [ 0.93128012,  0.08704707, -1.05771093,  0.31424733, -0.47917424,\n",
       "         0.64768854, -0.46341769,  0.54256004,  0.61167629,  1.0035329 ,\n",
       "         0.8219025 ,  1.53803657,  0.73846658, -0.21967189, -0.8084936 ,\n",
       "         0.09176078, -1.95967012,  0.51326743,  1.03099952, -2.6197451 ,\n",
       "         0.49671415,  0.09707755, -0.46572975,  0.91540212,  1.56464366,\n",
       "         1.46564877, -0.60063869, -0.03582604, -0.60170661, -1.19620662,\n",
       "         0.35711257,  0.37569802,  0.26105527, -0.5297602 , -0.90802408,\n",
       "         0.19686124, -0.29900735,  0.36163603,  0.82254491, -0.29169375,\n",
       "         0.36139561, -0.676922  ,  1.52302986, -0.51827022, -0.23415337,\n",
       "        -0.39210815, -0.3011037 , -0.64511975,  0.32875111,  0.2088636 ,\n",
       "        -0.32766215,  0.00511346, -0.23413696,  1.47789404, -0.38508228,\n",
       "         0.34361829,  0.33126343, -0.18565898, -0.23458713, -1.98756891,\n",
       "         0.32408397, -0.2257763 , -1.10633497, -0.70205309, -1.46351495,\n",
       "         0.96864499, -1.72491783, -1.91328024, -0.56228753,  0.76743473,\n",
       "         0.81252582, -1.4123037 , -1.47852199, -1.22084365, -0.83921752,\n",
       "         1.57921282,  0.97554513,  0.24196227,  0.29612028, -0.54438272,\n",
       "        -1.76304016,  0.11092259,  0.17136828, -1.32818605,  1.05712223,\n",
       "        -0.11564828, -0.46947439, -0.01349722, -1.01283112, -0.1382643 ,\n",
       "        -1.15099358,  1.35624003,  0.0675282 , -0.50175704, -0.46063877,\n",
       "         1.85227818, -1.42474819, -0.71984421, -0.07201012, -0.30921238]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "x, y = make_regression(n_samples = 100, n_features = 1,\n",
    "                       n_informative = 1, noise = 10, random_state = 42)\n",
    "  \n",
    "\n",
    "  \n",
    "# Adding x0=1 column to x array.\n",
    "X_New = np.array([np.ones(len(x)), x.flatten()])\n",
    "X_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jaxl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjaxl\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jaxl'"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jaxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "(5, 4) (4, 1) (5,)\n",
      "[13.248629]\n",
      "[2.5007424]\n",
      "[10.753599]\n",
      "[12.281649]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13.24863019,  2.50074284, 10.75359912, 12.28164862])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import pandas as pd\n",
    "x, y = make_regression(n_samples = 5, n_features = 1,\n",
    "                       n_informative = 1, noise = 0, random_state = 42)\n",
    "\n",
    "print(type(x))\n",
    "N = 5\n",
    "P = 3\n",
    "X = pd.DataFrame(np.random.randn(N, P))\n",
    "y = pd.Series(np.random.randn(N))\n",
    "theta = np.ones((P+1, 1),dtype = float)\n",
    "print(theta)\n",
    "#X_fit = np.array([np.ones(len(X)), X.flatten()]).transpose()\n",
    "X_fit = X.copy(deep=True)\n",
    "X_fit.insert(loc = 0, column = -1 , value = np.ones(X.shape[0]))\n",
    "X_fit=X_fit.to_numpy()\n",
    "y=y.to_numpy()\n",
    "print(X_fit.shape,theta.shape,y.shape)\n",
    "mse_grad = 2*np.mean(X_fit.T @ (X_fit @ (theta) - y),axis=1)\n",
    "def f(theta, X_fit, y ):\n",
    "    #return ((y - (X_fit @ theta))**2).mean()\n",
    "    return np.mean((y - (X_fit @ theta)).T @ (y - (X_fit @ theta)))\n",
    "mse_grad1 = jax.grad(f,argnums=0)(theta,X_fit,y)\n",
    "for i in mse_grad1:\n",
    "    print(i)\n",
    "mse_grad.reshape(4,1)\n",
    "mse_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'type' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m]) \u001b[39m@\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39;49m\u001b[39mnumpy\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39min\u001b[39;49;00m \u001b[39mtype\u001b[39;49m(a):\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(a)\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'type' is not iterable"
     ]
    }
   ],
   "source": [
    "a=np.array([1]) @ np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
    "print(x.shape)\n",
    "xt=np.transpose(x)\n",
    "print(xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  8, 12],\n",
       "       [16, 20, 24]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[[1,2,3],[4,5,6]]\n",
    "k = np.array(l)\n",
    "k*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'linearRegression'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlinearRegression\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_regression\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearRegression\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error \u001b[39mas\u001b[39;00m mse\n\u001b[1;32m     16\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m45\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'linearRegression'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Q2_test.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1R-h6mR7sy_h7Yi1dKE4xCb8nKprgkVDj\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from linearRegression.linear_regression import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "np.random.seed(45)\n",
    "\n",
    "N = 90\n",
    "P = 10\n",
    "X = pd.DataFrame(np.random.randn(N, P))\n",
    "y = pd.Series(np.random.randn(N))\n",
    "\n",
    "import time\n",
    "\n",
    "    \n",
    "\n",
    "LR = LinearRegression(fit_intercept=True)\n",
    "\n",
    "# Call Gradient Descent here\n",
    "print(\"Gradient Type: Manual\")\n",
    "time1 = time.time()\n",
    "for i in range(10):\n",
    "    LR.fit_gradient_descent(X, y, batch_size=0, gradient_type='manual', penalty_type = 'unregularized', num_iters=10, lr=0.01)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--Unregularized rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "\n",
    "time1 = time.time()\n",
    "for i in range(10):\n",
    "    LR.fit_gradient_descent(X, y, batch_size=0, gradient_type='manual', penalty_type = 'l2', num_iters=10, lr=0.01)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--L2 rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "print(\"Gradient Type: JAX\")\n",
    "time1 = time.time()\n",
    "for i in range(10):\n",
    "    LR.fit_gradient_descent(X, y, batch_size=0, gradient_type='jax', penalty_type = 'unregularized', num_iters=10, lr=0.01)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--Unregularized rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "\n",
    "time1 = time.time()\n",
    "for i in range(10):\n",
    "    LR.fit_gradient_descent(X, y, batch_size=0, gradient_type='jax', penalty_type = 'l1', num_iters=10, lr=0.01)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--L1 rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "\n",
    "time1 = time.time()\n",
    "for i in range(10): \n",
    "    LR.fit_gradient_descent(X, y, batch_size=0, gradient_type='jax', penalty_type = 'l2', num_iters=10, lr=0.01)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--L2 rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "print(\"Running SGD with ridge regularization\")\n",
    "time1 = time.time()\n",
    "for i in range(10):\n",
    "    LR.fit_gradient_descent(X, y, batch_size=1, gradient_type='manual', penalty_type = 'l2', num_iters=10, lr=0.01)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "print(\"---------------------------\")\n",
    "\n",
    "print(\"Running mini-batch SGD with ridge regularization\")\n",
    "time1 = time.time()\n",
    "for i in range(10):\n",
    "    LR.fit_gradient_descent(X, y, batch_size=10, gradient_type='manual', penalty_type = 'l2', num_iters=10, lr=0.01)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "\n",
    "\n",
    "print(\"Running SGD with momentum and ridge regularization\")\n",
    "time1 = time.time()\n",
    "for i in range(10):\n",
    "    LR.fit_SGD_with_momentum(X, y, gradient_type='manual', penalty_type = 'l2', num_iters=10, lr=0.01, beta=0.9)\n",
    "time2 = time.time()\n",
    "y_hat = LR.predict(X)\n",
    "print(\"--rmse: \", np.sqrt(mse(y,y_hat)))\n",
    "print(\"time taken: \", (time2-time1/10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
