# -*- coding: utf-8 -*-
"""Q5_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19fLBYgrxvEcH2qfm0URlFaLuEUyLMibB
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from preprocessing.polynomial_features import PolynomialFeatures
from linearRegression.linear_regression import LinearRegression
from sklearn.datasets import make_regression
import os.path
from os import path
from sklearn.preprocessing import StandardScaler

if not path.exists('Plots/Question5/'):
    os.makedirs('Plots/Question5/')

# TODO : Write here



#Preprocess the input using the polynomial features

for n_samples in range(1000,5500,1000):
    X, y = make_regression(n_samples=n_samples, n_features=1, noise=20, random_state=45)
    # X = np.array([i*np.pi/180 for i in range(60+n_samples,300+n_samples,2)])
    # y = 3*X + 8 + np.random.normal(0,3,len(X))
    # X=X.reshape(-1,1)
    # X = np.random.rand(n_samples, 1)
    # y = X.squeeze()**2 + 0.1*np.random.randn(n_samples)
    norm = []
    for degree in [1,3,5,7,9]:
        poly = PolynomialFeatures(degree=degree,include_bias=True)
        X_train = np.array([])
        for i in range(len(X)):
            if X_train.shape[0] != 0:
                X_train = np.vstack((X_train,poly.transform(X[i])))
            else:
                X_train = poly.transform(X[i])
        X_train = StandardScaler().fit_transform(X_train)
        LR = LinearRegression(fit_intercept=True)
        theta = LR.fit_sklearn_LR(X_train,y)
        norm.append(np.linalg.norm(theta))
    # norm = np.array(norm)
    # norm = norm/np.linalg.norm(norm)
    plt.plot([1,3,5,7,9],norm,label="n_samples = "+str(n_samples))
plt.title("Norm(θ) vs Degree for varying samples")
plt.xlabel("Degree")
plt.ylabel("Norm(θ)")
plt.legend()
plt.savefig('Plots/Question5/Degree = '+str(degree)+'2.png')
plt.show()